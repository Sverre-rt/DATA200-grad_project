{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 200 - Grad Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sverre Rynning-Tønnesen, Isabel Slorer, Hans Erik Heum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Introduction <br>\n",
    "2) Data Sampling and Collection <br>\n",
    "3) Data Cleaning <br>\n",
    "4) Exploratory Data Analysis <br>\n",
    "5) Feature Engineering <br>\n",
    "6) Data Modeling and Inferences <br>\n",
    "7) Conclusion <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vet ikke helt hva vi skal ha med her enda, kanskje en forklaring på notebooken, evt samme som står i Abstract i rapporten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sampling and Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her må vi skrive om hvordan vi har hentet dataen.\n",
    "Nevne at vi henter ekstern data, og fra en annen oppgave. Hvorfor?\n",
    "\n",
    "How were the data collected? <br>\n",
    "Was there any potential bias introduced in the sampling process?\n",
    "\n",
    "\n",
    "#____________Kommentarer: <br>\n",
    "Skal vi vise head på hvert eneste dataframe vi laster inn??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all important libraries\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from zipfile import ZipFile\n",
    "import datetime\n",
    "\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "import plotly as go\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "from plotly.offline import iplot, init_notebook_mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#initialize state_social_distancing_d\n",
    "def init_state_social_distancing_actions(path):\n",
    "  df_master = pd.DataFrame()\n",
    "  flag = False\n",
    "  files_in_folder = glob.glob(path)\n",
    "  for filename in files_in_folder:    \n",
    "    zip_file = ZipFile(filename)\n",
    "    for text_file in zip_file.infolist():\n",
    "      # if not text_file.filename.startswith('__MACOSX/'):\n",
    "      if text_file.filename.endswith('.csv'):\n",
    "        date = re.search('\\d*-\\d*-\\d*', text_file.filename)[0]\n",
    "        if date == \"20201-06-01\":\n",
    "          date = \"2021-06-01\"\n",
    "        date_time_value = pd.to_datetime(date)\n",
    "        df = pd.read_csv(zip_file.open(text_file.filename), sep=\",\", header=0)\n",
    "        df[\"Date\"] = date_time_value\n",
    "        df.rename(columns = {'Unnamed: 0':'State'}, inplace = True)\n",
    "        df.drop((df[df.State.isin([\"United States\"])].index) | (df[df.State.isnull()].index), inplace=True)\n",
    "      if not flag:\n",
    "        df_master = df\n",
    "        flag = True\n",
    "      else:\n",
    "        df_master = pd.concat([df_master, df])\n",
    "  df_master.set_index([\"Date\", \"State\"], inplace=True)\n",
    "  df_master.sort_index(inplace=True)\n",
    "  return df_master\n",
    "\n",
    "state_social_distancing_actions = init_state_social_distancing_actions(r'**csv_files/state_social_distancing_actions.zip')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import vaccination data\n",
    "\n",
    "Hvis man skal være helt nazi og konsis, så skal man kun ta 'CA' som Location for data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_vaccination_df_from_zip(path, index_col):\n",
    "    df_master = pd.read_csv(glob.glob(path)[0], compression='zip', header=0, sep=',', index_col=index_col)\n",
    "    return df_master\n",
    "\n",
    "vaccination_df = init_vaccination_df_from_zip(r'**csv_files/COVID-19_Vaccinations_in_the_United_States_Jurisdiction.csv.zip', [\"Date\"])\n",
    "vaccination_df = vaccination_df[vaccination_df[\"Location\"] == \"CA\"]\n",
    "vaccination_df.index = pd.to_datetime(vaccination_df.index)\n",
    "vaccination_df.sort_index(inplace=True)\n",
    "vaccination_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import death rate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_daily_reports(path):\n",
    "  df_master = pd.DataFrame()\n",
    "  flag = False\n",
    "  files_in_folder = glob.glob(path)\n",
    "  for filename in files_in_folder:    \n",
    "    zip_file = ZipFile(filename)\n",
    "    for text_file in zip_file.infolist():\n",
    "      # if not text_file.filename.startswith('__MACOSX/'):\n",
    "      if text_file.filename.endswith('.csv'):\n",
    "        date = re.search('\\d*-\\d*-\\d*', text_file.filename)[0]\n",
    "        date_time_value = pd.to_datetime(date)\n",
    "        df = pd.read_csv(zip_file.open(text_file.filename), sep=\",\", header=0)\n",
    "        df[\"Date\"] = date_time_value\n",
    "        df.rename(columns = {'Province_State':'State'}, inplace = True)\n",
    "        df.drop((df[df.State.isin([\"United States\"])].index) | (df[df.State.isnull()].index), inplace=True)\n",
    "      if not flag:\n",
    "        df_master = df\n",
    "        flag = True\n",
    "      else:\n",
    "        df_master = pd.concat([df_master, df])\n",
    "  df_master.set_index([\"Date\", \"State\"], inplace=True)\n",
    "  df_master.sort_index(inplace=True)\n",
    "  return df_master\n",
    "\n",
    "covid_daily_reports = init_daily_reports(r'**csv_files/csse_covid_19_daily_reports_us.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import infection data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_infection_dataframe_from_zip(path, index_col):\n",
    "    df_master = pd.read_csv(glob.glob(path)[0], compression='zip', header=0, sep=',', index_col=index_col)\n",
    "    return df_master\n",
    "\n",
    "infected_df = init_infection_dataframe_from_zip(r'**csv_files/United_States_COVID-19_Cases_and_Deaths_by_State_over_Time.csv.zip', [\"submission_date\", \"state\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import death counts by sex, age & state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sex_age = pd.read_csv('csv_files/cdc_death_counts_by_sex_age_state.zip',header=0)\n",
    "df_sex_age.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import death counts by conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_condition = pd.read_csv('csv_files/cdc_death_counts_by_conditons.zip',header=0)\n",
    "df_condition.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import anxiety data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anx_dep = pd.read_csv('csv_files/nchs_covid_indicators_of_anxiety_depression.zip',header=0)\n",
    "df_anx_dep.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What type of data are you currently exploring? <br>\n",
    "What is the granularity of the data? <br>\n",
    "What does the distribution of the data look like? Are there any outliers? Are there any missing or invalid entries? <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_state_social_distancing_actions(df):\n",
    "  df = df.drop(columns=[\"Primary Election Postponement\"])\n",
    "  return df\n",
    "\n",
    "cleaned_state_social_distancing_actions = clean_state_social_distancing_actions(state_social_distancing_actions)\n",
    "cleaned_state_social_distancing_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up the dataframe to remove unused columns and solve for Nan fields. \n",
    "- Have to manually insert face mask requirements for recent months based on: https://statepolicies.com/data/graphs/face-masks/\n",
    "- Face mask mandate was reintroduced from Dec 15, 2021 -> Feb 15, 2022\n",
    "\n",
    "Other changes\n",
    "- Manually inserted \"No Limit\" after 2021-08-15 because missing data"
   ]
  },
  {

   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],

   "source": [
    "#### Clean restriction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "california_data = cleaned_state_social_distancing_actions[cleaned_state_social_distancing_actions.index.get_level_values('State').isin(['California'])]\n",
    "california_data.reset_index(\"State\", inplace=True)\n",
    "california_data = california_data[~california_data.index.duplicated(keep='first')]\n",
    "# Fill inn missing dates with rows equal the previous date with data\n",
    "days_idx = pd.date_range(start=california_data.index[0], end=\"2022-04-18\", freq=\"D\")\n",
    "california_data = california_data.reindex(days_idx, method=\"pad\")\n",
    "# Update facemask data\n",
    "california_data.loc[: \"2020-06-17\", \"Face Covering Requirement\"] = 0 # No\n",
    "california_data.loc[\"2020-06-18\" : \"2021-06-14\", \"Face Covering Requirement\"] = 1 # Yes\n",
    "california_data.loc[\"2021-06-15\" : \"2021-12-14\", \"Face Covering Requirement\"] = 0\n",
    "california_data.loc[\"2021-12-15\" : \"2022-02-14\", \"Face Covering Requirement\"] = 1\n",
    "california_data.loc[\"2022-02-15\" : , \"Face Covering Requirement\"] = 0\n",
    "# Manually insert gathering limit for missing values\n",
    "california_data.loc[\"2021-08-16 \":, \"Large Gatherings Ban\"] = \"No Limit\"\n",
    "# Transform Large Gatherings Ban to a sevearity of the rules (1: no restrictions, 5: All gatherings prohibited)\n",
    "california_data[\"Large Gatherings Ban\"].replace({'All Gatherings Prohibited': 5, '>50 Prohibited': 4, 'Expanded Limit to 25 or Fewer': 3, '>25 Prohibited': 3, '>10 Prohibited': 2, 'No Limit': 1}, inplace=True)\n",
    "# Set the missing restaurant values to open\n",
    "california_data[california_data[\"Restaurant Limits\"].isna()][\"Restaurant Limits\"] = \"Open\"\n",
    "\n",
    "ohe_restaurant_limits = pd.get_dummies(california_data[\"Restaurant Limits\"], prefix='Restaurant Limits', columns = 'Restaurant Limits')\n",
    "\n",
    "selected_ca_restrictions = pd.concat([california_data[[\"Face Covering Requirement\", \"Large Gatherings Ban\"]], ohe_restaurant_limits], axis=1)\n",
    "\n",
    "#selected_ca_restrictions = california_data[[\"Face Covering Requirement\", \"Large Gatherings Ban\"]]\n",
    "selected_ca_restrictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean vaccination data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add ekstra columns to have the same time-range as the other datasets\n",
    "- Insert 0 as the number of vaccinated since no-one was vaccinated at the first date of the current df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_idx = pd.date_range(start=\"2020-06-04\", end=\"2020-12-13\", freq=\"D\")\n",
    "days_with_missing_data = vaccination_df.reindex(days_idx, fill_value=0)\n",
    "days_with_missing_data[\"Location\"] = \"CA\"\n",
    "days_with_missing_data.index.names = ['Date']\n",
    "vaccination_df = days_with_missing_data.append(vaccination_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaccination_df_administered = pd.DataFrame(vaccination_df[\"Administered\"])\n",
    "vaccination_df_administered.rename(columns={\"Administered\": \"Total Vaccines Administered\"}, inplace=True)\n",
    "vaccination_df_administered\n",
    "\n",
    "vaccination_df_administered[\"Daily vaccinations\"] = vaccination_df_administered.diff(periods=1)\n",
    "vaccination_df_administered = vaccination_df_administered[~vaccination_df_administered.index.duplicated(keep='first')]\n",
    "vaccination_df_administered.loc[\"2020-06-04\", \"Daily vaccinations\"] = 0\n",
    "vaccination_df_administered[(vaccination_df_administered[\"Daily vaccinations\"] == 0) | (vaccination_df_administered[\"Daily vaccinations\"] < 0)]\n",
    "\n",
    "# Becuase there is a mistake in the data on 2022-01-27 where the total number of vaccines suddenly drops by -1593072 we have to solve this\n",
    "# and chose to do it with setting this value to 0\n",
    "vaccination_df_administered.loc[\"2022-01-27\", \"Daily vaccinations\"] = 0\n",
    "vaccination_df_administered = vaccination_df_administered[[\"Daily vaccinations\"]]\n",
    "vaccination_df_administered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Total Vaccines from incremental to day by day number of "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean daily covid deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_daily_reports = covid_daily_reports.reset_index()\n",
    "states = ['California']\n",
    "covid_daily_reports = covid_daily_reports[covid_daily_reports[\"State\"].isin(states) == True]\n",
    "covid_daily_reports.set_index([\"Date\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths_data = pd.DataFrame(covid_daily_reports[\"Deaths\"])\n",
    "deaths_data[\"Daily Deaths\"] = deaths_data.diff(periods=1)\n",
    "deaths_data = deaths_data[~deaths_data.index.duplicated(keep='first')]\n",
    "deaths_data.drop([\"Deaths\"], axis=1, inplace=True)\n",
    "# For all the values where the death count is less than 0 we set the value to be equal 0\n",
    "deaths_data[deaths_data[\"Daily Deaths\"] < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean infection rate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "infected_df.index = infected_df.index.set_levels([pd.to_datetime(infected_df.index.levels[0]), infected_df.index.levels[1]])\n",
    "infected_df_CA = infected_df[infected_df.index.get_level_values('state').isin(['CA'])]\n",
    "infected_df_CA = infected_df_CA.reset_index()\n",
    "infected_df_CA.set_index([\"submission_date\"], inplace=True)\n",
    "infected_df_CA = infected_df_CA[[\"tot_cases\"]].sort_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure all dataframes share the same date-time range\n",
    "- selected_ca_restrictions: 2020-06-04 - 2022-04-18\t\n",
    "- vaccination_df: 2020-06-04 - 2022-04-20\n",
    "- Death data: 2020-04-12 - 2022-03-28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.concat([selected_ca_restrictions[\"2020-06-04\" : \"2022-03-28\"], vaccination_df_administered[\"2020-06-04\" : \"2022-03-28\"], infected_df_CA[\"2020-06-04\" : \"2022-03-28\"], deaths_data[\"2020-06-04\" : ]], axis=1)\n",
    "merged_data.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean deaths by sex, age & state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kommentere hvorfor vi fjerner dette\n",
    "states = ['Alabama','Alaska','Arizona','Arkansas','California','Colorado','Connecticut','Delaware','Florida','Georgia','Hawaii','Idaho','Illinois','Indiana','Iowa','Kansas','Kentucky','Louisiana','Maine','Maryland','Massachusetts','Michigan','Minnesota','Mississippi','Missouri','Montana','Nebraska','Nevada','New Hampshire','New Jersey','New Mexico','New York','North Carolina','North Dakota','Ohio','Oklahoma','Oregon','Pennsylvania','Rhode Island','South Carolina','South Dakota','Tennessee','Texas','Utah','Vermont','Virginia','Washington','West Virginia','Wisconsin','Wyoming']\n",
    "df_sex_age = df_sex_age[df_sex_age[\"State\"].isin(states) == True]\n",
    "df_sex_age = df_sex_age[df_sex_age[\"Group\"]== 'By Month']\n",
    "\n",
    "df_sex_age[\"End Date\"] = pd.to_datetime(df_sex_age[\"End Date\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean condition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_condition = df_condition[df_condition[\"State\"].isin(states) == True]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean anxiety data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anx_dep2 = df_anx_dep[df_anx_dep['State']=='California']\n",
    "\n",
    "merged_no_index = merged_data.copy().reset_index()\n",
    "merged_no_index['index'] = pd.to_datetime(merged_no_index['index'])\n",
    "restriction_mental = pd.DataFrame()\n",
    "for index, row in df_anx_dep2.iterrows():\n",
    "    first_date = pd.to_datetime(row['Time Period Start Date'])\n",
    "    last_date = pd.to_datetime(row['Time Period End Date'])\n",
    "    \n",
    "    interval_rows = merged_no_index[(merged_no_index['index']>= first_date) & (merged_no_index['index']<= last_date)]\n",
    "    interval_rows = pd.DataFrame(interval_rows.mean()).T\n",
    "    row = pd.DataFrame(row).T\n",
    "    interval_rows.rename(index={0:row.index[0]},inplace=True) \n",
    "    result = pd.concat([row,interval_rows], axis=1,join='inner')\n",
    "    restriction_mental = pd.concat([restriction_mental,result],axis = 0)\n",
    "    \n",
    "restriction_mental= restriction_mental.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Her må vi diskutere hva som skal være i Feature Engineering og hva som som skal være i Cleaning\n",
    "\n",
    "restriction_mental['Value'] = restriction_mental['Value'].astype(float)\n",
    "restriction_mental = restriction_mental.groupby('Time Period End Date').mean()\n",
    "restriction_mental.index = pd.to_datetime(restriction_mental.index)\n",
    "restriction_mental = restriction_mental.sort_index()\n",
    "restriction_mental = restriction_mental.drop([\"Time Period\",'Low CI','High CI'], axis=1)\n",
    "restriction_mental.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her har vi ikke så mye enda, men her skal vi egentlig plotte ting som gjør at vi forstår dataen bedre. <br>\n",
    "Altså ikke nødvendigvis plots som vi bruker for å forstå feks sammenhengen mellom restriksjoner og dødsfall, men mer som feks relationplots, outliers, etc - bedre forståelse av selve dataen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA death by sex, age & state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To-Do\n",
    "#Legge på tittel på begge nullplotsene, og legge de inn ved siden av hverandre\n",
    "\n",
    "\n",
    "\n",
    "#sns.heatmap(df_condition.isnull(),yticklabels = False, cbar = False, cmap='viridis')\n",
    "#As we can see on the plot below, not many of our columns (that we are currently using) contains a lot of null values.\n",
    "#Except Covid 19-Deaths.. we should look further into that.\n",
    "\n",
    "sns.heatmap(df_sex_age.isnull(),yticklabels = False, cbar = False, cmap='viridis')\n",
    "#As we can see there are a LOT of null values in important columns..\n",
    "#Before we decide to with them lets remove irrelevant rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation\n",
    "\n",
    "As we can see on the correlation plot, and also in the list of the most Daily Death's most correlated values, we can see that the columns adressing openings of restaurants and Face Covering Requirements are the most correlated with Daily Deaths. This makes them important features when it comes to predicting _Daily Deaths_. <br> <br>\n",
    "\n",
    "Looking at the map of correlations we can see that _Face Covering Requirements_ and _Large Gathering Bans_ are heavily correlated. This makes sense when it comes to implementations of restrictions. Another noticable trait in the plot is the heavy negative correlation between _Large Gathering Bans_ and _number of total cases_. This can be interpreted as when the large gathering bans value raises (which determines how strict the gathering bans are) the total cases of covid gets reduced.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['Face Covering Requirement'] = merged_data['Face Covering Requirement'].astype(int)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(8,10))\n",
    "plt.title('Correlation between features in the dataset')\n",
    "sns.heatmap(merged_data.corr(),linewidth=0.5,cmap=\"Blues\", square=True,annot=True)\n",
    "\n",
    "correlation = merged_data.corr()\n",
    "print(\"Daily Death's most correlated features: \\n\")\n",
    "print(abs(correlation['Daily Deaths']).sort_values(ascending = False), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better overview of the most important features, we made a correlation plot directly with Daily Deaths.\n",
    "We notice that it is usually more deaths when there are stricter restrictions. This makes sense considering why the government implements restrictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2,ax3) = plt.subplots(1,3 ,figsize=(15,4))\n",
    "var = 'Face Covering Requirement' \n",
    "data = pd.concat([merged_data['Daily Deaths'], merged_data[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='Daily Deaths', ax=ax1);\n",
    "var = 'Restaurant Limits_Reopened to Dine-in Service with Capacity Limits'\n",
    "data = pd.concat([merged_data['Daily Deaths'], merged_data[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='Daily Deaths',ax=ax2);\n",
    "var = 'Restaurant Limits_Open'\n",
    "data = pd.concat([merged_data['Daily Deaths'], merged_data[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='Daily Deaths',ax=ax3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did the same analysis on the mental health data merged with restrictions. \n",
    "The value the determines how the average mental health is in California is noticeable correlated with _Restaurant Limits_Reopened to Dine-in Service with Capacity Limits_ and _Large Gatherings Ban_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f, ax = plt.subplots(figsize=(8,10))\n",
    "plt.title('Correlation between features in the dataset')\n",
    "sns.heatmap(restriction_mental.corr(),linewidth=0.5,cmap=\"Blues\", square=True,annot=True)\n",
    "\n",
    "correlation = restriction_mental.corr()\n",
    "print(\"Mental Health most correlated features: \\n\")\n",
    "print(abs(correlation['Value']).sort_values(ascending = False), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers\n",
    "\n",
    "**Kan argumentere for at dette skal flyttes til Data Cleaning, men vet at det er nokså vanlig å ha det her også.** <br>\n",
    "\n",
    "To get a better understanding of the shape, variability and the center of our statistical data, we make several boxplots. We make a boxplot for the most important features, or the only ones that numerical for each retrieved dataset. <br>\n",
    "In the first dataset there are no outliers for _Daily vaccinations_ or _tot_cases_. Looking at the _Daily Deaths_ however it is noticable many datapoints outside the maximum whisker (Q3+1.5*IQR). These datapoints would normally be interpreted as outliers and hence removed. Due to some domain knowledge and research regarding Covid-19 we understood that the number of Daily Deaths is a variable with high variance. For instance, the parameter would have suddent increases during the development of new contagious covid variants. Therefore, even though it most likely will infect our model and predctions, we decided not to interpret them as outliers and therefore keep the values. <br>\n",
    "\n",
    "Looking at the boxplot for the _Value_ that determines levels of mental health, we see that there are no outliers. This is good for decreasing variance in our model and increasing statistical power. One reason for the absence of outliers is that we averaged our mental health data values for each group of anxiety-category. This will cause outliers to be less outstanding. <br>\n",
    "\n",
    "Below we have plotted boxplots for the datasets containing Covid-19 related deaths based on sex, age and conditions. Many outliers are visible in these pots. For the same reason to include covid 19 outliers mentioned above, we chose to keep the outliers in these datasets as well. Outstanding covid 19 deaths are very interesting for our analysis to get a better understanding of what is causing these 'spikes'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, (ax1,ax2) = plt.subplots(1,2,figsize=(15,4))\n",
    "ax1.title.set_text('Boxplots of params in Daily Covid Dataset')\n",
    "ax2.title.set_text('Boxplot of Value in mental health Dataset')\n",
    "merged_data.boxplot(column=['Daily vaccinations','tot_cases','Daily Deaths'],ax=ax1)\n",
    "restriction_mental.boxplot(column=['Value'],ax=ax2)\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(1,2,figsize=(15,4))\n",
    "ax1.title.set_text('Boxplots of params in Covid Deaths by age dataset')\n",
    "ax2.title.set_text('Boxplot of Covid-19 Deaths in Condition Dataset')\n",
    "df_sex_age.boxplot(column=['Total Deaths','Pneumonia Deaths','Influenza Deaths','Pneumonia, Influenza, or COVID-19 Deaths'],ax=ax1)\n",
    "df_condition.boxplot(column=['COVID-19 Deaths'],ax=ax2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data[\"Daily vaccinations\"] = np.log(merged_data[\"Daily vaccinations\"] + 1).fillna(0)\n",
    "merged_data[\"tot_cases\"] = np.log(merged_data[\"tot_cases\"] + 1).fillna(0)\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Modeling and Inferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Deaths in California by Sex, Age & Condition <br>\n",
    "2) Plot of Mental Health Value in the US over the year <br>\n",
    "3) Prediciton of Death Rates based on restrictions <br>\n",
    "4) Prediciton of Mental Health based on restrictions and Death Rates <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deaths in California by Sex, Age & Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_notebook_mode()\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "df_sex_age_grouped = pd.DataFrame(df_sex_age.groupby(['End Date','Age Group'])[\"COVID-19 Deaths\"].sum())\n",
    "df_sex_age_grouped = df_sex_age_grouped.reset_index()\n",
    "#fig.add_trace(go.Scatter(grouped_df_age, x=\"End Date\", y='COVID-19 Deaths', color=\"Age Group\",line_group=\"Age Group\"))\n",
    "#region, geo_region in geo.groupby('Geographical region'):\n",
    "    \n",
    "for name, frame in df_sex_age_grouped.groupby('Age Group'):\n",
    "    fig.add_scatter(x=frame['End Date'], y=frame['COVID-19 Deaths'], name=name, mode='lines')\n",
    "\n",
    "fig.update_layout(title='Total Deaths in the USA by year and age',xaxis={'title':'Date'},yaxis={'title':'Number of Deaths'})\n",
    "iplot(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "df_sex_age_cali = df_sex_age[df_sex_age['State']=='California']\n",
    "df_sex_age_grouped = pd.DataFrame(df_sex_age_cali.groupby(['End Date','Age Group'])[\"COVID-19 Deaths\"].sum())\n",
    "df_sex_age_grouped = df_sex_age_grouped.reset_index()\n",
    "#display(grouped_df_age)\n",
    "#fig.add_trace(go.Scatter(grouped_df_age, x=\"End Date\", y='COVID-19 Deaths', color=\"Age Group\",line_group=\"Age Group\"))\n",
    "\n",
    "#region, geo_region in geo.groupby('Geographical region'):\n",
    "    \n",
    "for name, frame in df_sex_age_grouped.groupby('Age Group'):\n",
    "    fig.add_scatter(x=frame['End Date'], y=frame['COVID-19 Deaths'], name=name, mode='lines')\n",
    "\n",
    "fig.update_layout(title='Total Deaths in California by year and age',xaxis={'title':'Date'},yaxis={'title':'Number of Deaths'})\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "df_sex_age_cali = df_sex_age[df_sex_age['State']=='California']\n",
    "df_sex_age_grouped = pd.DataFrame(df_sex_age_cali.groupby(['End Date','Sex'])[\"COVID-19 Deaths\"].sum())\n",
    "df_sex_age_grouped = df_sex_age_grouped.reset_index()\n",
    "#display(grouped_df_age)\n",
    "#fig.add_trace(go.Scatter(grouped_df_age, x=\"End Date\", y='COVID-19 Deaths', color=\"Age Group\",line_group=\"Age Group\"))\n",
    "\n",
    "#region, geo_region in geo.groupby('Geographical region'):\n",
    "    \n",
    "for name, frame in df_sex_age_grouped.groupby('Sex'):\n",
    "    fig.add_scatter(x=frame['End Date'], y=frame['COVID-19 Deaths'], name=name, mode='lines')\n",
    "\n",
    "fig.update_layout(title='Total Deaths in California by year and Sex',xaxis={'title':'Date'},yaxis={'title':'Number of Deaths'})\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_notebook_mode()\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "grouped_df_condition = pd.DataFrame(df_condition.groupby(['End Date','Condition Group'])[\"COVID-19 Deaths\"].sum())\n",
    "grouped_df_condition = grouped_df_condition.reset_index()\n",
    "#display(grouped_df_age)\n",
    "#fig.add_trace(go.Scatter(grouped_df_age, x=\"End Date\", y='COVID-19 Deaths', color=\"Age Group\",line_group=\"Age Group\"))\n",
    "\n",
    "fig = go.Figure()\n",
    "#region, geo_region in geo.groupby('Geographical region'):\n",
    "    \n",
    "for name, frame in grouped_df_condition.groupby('Condition Group'):\n",
    "    fig.add_scatter(x=frame['End Date'], y=frame['COVID-19 Deaths'], name=name, mode='lines')\n",
    "fig.update_layout(title='Total Deaths in California by year and Condition',xaxis={'title':'Date'},yaxis={'title':'Number of Deaths'})\n",
    "iplot(fig)\n",
    "\n",
    "#Kommentar til figuren og datasettet\n",
    "#Vet ikke helt om en som dør av respiratory diseases blir påvirket av covid-death..\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average Mental Health in US over the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = pd.DataFrame(df_anx_dep.groupby('Time Period End Date')['Value'].mean()).reset_index()\n",
    "grouped['Time Period End Date'] = pd.to_datetime(grouped[\"Time Period End Date\"])\n",
    "\n",
    "grouped = grouped.sort_values(by ='Time Period End Date')\n",
    "grouped\n",
    "\n",
    "plt.plot(grouped['Time Period End Date'],grouped['Value'])\n",
    "plt.title('Average Mental Health Value in US over the year')\n",
    "plt.xlabel('year')\n",
    "plt.ylabel('value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restrictions and Total Deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#face_mask_ on = pd.to_datetime('2020-06-18')\n",
    "\n",
    "#restriction_mental\n",
    "merged_data_2 = merged_data.copy() \n",
    "merged_data_2['Face Change'] = merged_data_2['Face Covering Requirement'].diff()\n",
    "merged_data_2['Restaurant Change'] = merged_data_2['Restaurant Limits_Open'].diff()\n",
    "\n",
    "mask_on = merged_data_2[(merged_data_2['Face Change']==1) | (merged_data_2['Face Change']==-1) ]\n",
    "restaurant_on = merged_data_2[(merged_data_2['Restaurant Change']==1) | (merged_data_2['Restaurant Change']==-1) ]\n",
    "plt.figure(figsize = (18,8))\n",
    "merged_data_2.reset_index(inplace=True)\n",
    "sns.lineplot(x = 'index', y = 'Daily Deaths',data = merged_data_2)\n",
    "my_label = \"mask on\"\n",
    "my_label2 = \"mask off\"\n",
    "\n",
    "for index, row in mask_on.iterrows():\n",
    "    if row['Face Change'] ==1:\n",
    "        plt.axvline(x = index, color = 'r',\n",
    "                label = my_label)\n",
    "        my_label = '_nolegend_'\n",
    "    else :\n",
    "        plt.axvline(x = index, color = 'g',\n",
    "                label = my_label2)\n",
    "        my_label2 = '_nolegend_'\n",
    "        \n",
    "my_label3 = \"restaurant close\"\n",
    "my_label4 = \"restarant open\"\n",
    "days = datetime.timedelta(3)\n",
    "for index, row in restaurant_on.iterrows():\n",
    "    if row['Restaurant Change'] ==1:\n",
    "        plt.axvline(x = index-days, color = 'b',\n",
    "                label = my_label3)\n",
    "        my_label3 = '_nolegend_'\n",
    "    else :\n",
    "        plt.axvline(x = index, color = 'y',\n",
    "                label = my_label4)\n",
    "        my_label4 = '_nolegend_'\n",
    "        \n",
    "        \n",
    "plt.legend()\n",
    "plt.title('Covid deaths together with Restrictions')\n",
    "plt.xlabel('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restriction_mental_2 = restriction_mental.copy() \n",
    "\n",
    "plt.figure(figsize = (18,8))\n",
    "restriction_mental_2.reset_index(inplace=True)\n",
    "\n",
    "sns.lineplot(x = 'Time Period End Date', y = 'Value',data = restriction_mental_2)\n",
    "\n",
    "my_label = \"mask on\"\n",
    "my_label2 = \"mask off\"\n",
    "\n",
    "for index, row in mask_on.iterrows():\n",
    "    if row['Face Change'] ==1:\n",
    "        plt.axvline(x = index, color = 'r',\n",
    "                label = my_label)\n",
    "        my_label = '_nolegend_'\n",
    "    else :\n",
    "        plt.axvline(x = index, color = 'g',\n",
    "                label = my_label2)\n",
    "        my_label2 = '_nolegend_'\n",
    "\n",
    "my_label3 = \"restaurant close\"\n",
    "my_label4 = \"restarant open\"\n",
    "\n",
    "for index, row in restaurant_on.iterrows():\n",
    "    if row['Restaurant Change'] ==1:\n",
    "        plt.axvline(x = index-days, color = 'b',\n",
    "                label = my_label3)\n",
    "        my_label = '_nolegend_'\n",
    "    else :\n",
    "        plt.axvline(x = index, color = 'y',\n",
    "                label = my_label)\n",
    "        my_label2 = '_nolegend_'\n",
    "        \n",
    "plt.legend()\n",
    "plt.title('Mental Health together with Restrictions')\n",
    "plt.xlabel('Date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_val = 5\n",
    "start_day = '2020-06-04'\n",
    "last_date = None\n",
    "dict_dates = {}\n",
    "\n",
    "for index, row in merged_data.iterrows():\n",
    "    if current_val != row['Large Gatherings Ban']:\n",
    "        dict_dates[start_day] = [last_date,current_val]\n",
    "        current_val = row['Large Gatherings Ban']\n",
    "        start_day = index\n",
    "    else:\n",
    "        last_date = index\n",
    "#Must add last value\n",
    "dict_dates[start_day] = [last_date,current_val]\n",
    "        \n",
    "color_dict = {5: '#7FFF00',4:'#458B00',3:'yellow',2:'#FF7F00',1:'red',0:'blue'}\n",
    "plt.figure(figsize = (18,8))\n",
    "ax =sns.lineplot(x = 'Time Period End Date', y = 'Value',data = restriction_mental_2)\n",
    "for key in dict_dates:\n",
    "    color = color_dict[dict_dates[key][1]]\n",
    "    ax.axvspan(key,dict_dates[key][0], color=color, alpha=0.5)\n",
    "\n",
    "\n",
    "ax.grid(color='#79818f', alpha=0.6, linestyle='solid', linewidth=0.7, axis='x')\n",
    "ax.grid(color='#2B2A27', alpha=0.6, linestyle='dashed', linewidth=0.7, axis='y')\n",
    "\n",
    "\n",
    "plt.title('Mental Health together with Large Gatherings')\n",
    "plt.xlabel('Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction of Death Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(merged_data, test_size = 0.1, random_state = 42)\n",
    "Y_train = train[\"Daily Deaths\"]\n",
    "X_train = train.drop([\"Daily Deaths\"], axis=1)\n",
    "\n",
    "linear_model = lm.LinearRegression(fit_intercept=True)\n",
    "linear_model.fit(X_train, Y_train)\n",
    "y_prediction = linear_model.predict(X_train)\n",
    "rmse = mean_squared_error(Y_train, y_prediction, squared=False)\n",
    "rmse\n",
    "plt.scatter(Y_train, Y_train-y_prediction, alpha=0.5);\n",
    "rmse\n",
    "\n",
    "#clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
    "#scores = cross_val_score(clf, X_train, Y_train, cv=5)\n",
    "#scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Followed example: https://towardsdatascience.com/improve-linear-regression-for-time-series-forecasting-e36f3c3e3534\n",
    "# https://github.com/cerlymarco/MEDIUM_NoteBook/blob/master/ModelTrees_TimeSeries/ModelTrees_TimeSeries.ipynb\n",
    "# https://github.com/cerlymarco/MEDIUM_NoteBook\n",
    "\n",
    "X_train_, X_test_, y_train_, y_test_ = train_test_split(\n",
    "    merged_data.drop('Daily Deaths', axis=1), \n",
    "    merged_data['Daily Deaths'], \n",
    "    test_size=0.3, shuffle=False)\n",
    "\n",
    "X_train_.shape, X_test_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOT STORE DATA ###\n",
    "\n",
    "y_train_.plot(label='train', figsize=(16,6))\n",
    "y_test_.plot(label='test')\n",
    "plt.title(\"State: {}\".format(\"California\")); plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = lm.LinearRegression(fit_intercept=True)\n",
    "\n",
    "#model = GridSearchCV(estimator=Ridge(), param_grid={'alpha': [1, 3, 5, 10, 20]}, \n",
    "#                     scoring='neg_mean_squared_error', cv=2, refit=True)\n",
    "model = lm.LinearRegression(fit_intercept=True)\n",
    "model.fit(X_train_, y_train_)\n",
    "\n",
    "pred_lr = pd.Series(model.predict(X_test_), index = y_test_.index)\n",
    "pred_lr.plot(label='linear_regression')\n",
    "y_test_.plot(label='true', figsize=(10,6));\n",
    "\n",
    "\n",
    "#model.best_params_\n",
    "\n",
    "# Total cases for the last 2 week for each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of days with deaths equal to 0\n",
    "#zero_death_days = merged_data.loc[merged_data[\"Daily Deaths\"] == 0]\n",
    "#zero_death_days.reset_index(inplace=True)\n",
    "#zero_death_days['weekday'] = zero_death_days['index'].dt.dayofweek # Monday=0, Sunday=6\n",
    "#zero_death_days\n",
    "\n",
    "## After not setting days with negative numbers equal to zero then there are 13 days equal to 0\n",
    "## 6 of them is a sunday, 6 is a saturday, and 1 is a monday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction of Mental Health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_, X_test_, y_train_, y_test_ = train_test_split(\n",
    "    restriction_mental.drop('Value', axis=1), \n",
    "    restriction_mental['Value'], \n",
    "    test_size=0.3, shuffle=False)\n",
    "\n",
    "model = lm.LinearRegression(fit_intercept=True)\n",
    "model.fit(X_train_, y_train_)\n",
    "\n",
    "#pred_lr = pd.Series(model.predict(X_test_), index = y_test_.index)\n",
    "#pred_lr.plot(label='linear_regression')\n",
    "#y_test_.plot(label='true', figsize=(10,6));\n",
    "\n",
    "pred_lr = pd.Series(model.predict(X_train_), index = y_train_.index)\n",
    "pred_lr.plot(label='linear_regression')\n",
    "y_train_.plot(label='true', figsize=(10,6));"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
